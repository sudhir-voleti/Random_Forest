---
title: "H2O autoML shinyapp funcs"
output:
  html_document:
    df_print: paged
---

### What is H2O?
H2O is the scalable open source ML platform that offers parallelized implementations of many supervised and unsupervised machine learning algorithms.

H2O installation requires Java Development Kit (JDK 11) be installed on your machines. [Go here](https://www.oracle.com/java/technologies/javase-downloads.html) and download Java SE 11 (not the latest Java SE 16!)

Why care abut H2O? Coz it enables **auto-ML** functionality. 

### About Auto-ML with h2o

Automated ML automates the supervised machine learning model training process. The current version of AutoML: 

* trains and cross-validates the following algorithms (in order) 
  - three pre-specified XGBoost GBM (Gradient Boosting Machine) models, 
  - a fixed grid of GLMs (Generalized linear models), 
  - a default Random Forest (DRF), 
  - five pre-specified H2O GBMs, 
  - a near-default Deep Neural Net, 
  - an Extremely Randomized Forest (XRT), 
  - a random grid of XGBoost GBMs, 
  - a random grid of H2O GBMs, and 
  - a random grid of Deep Neural Nets. 

In some cases, there will not be enough time to complete all the algorithms, so some may be missing from the *leaderboard*. AutoML then trains two Stacked Ensemble models, one of all the models, and one of only the best models of each kind.

Recall the menu example I mentioned? Auto-ML is the future coz not only shows you a menu, but the entire buffet. 

* Auto-ML ke advantages
  - One can sample from different models
  - tweak this model or that, 
  - mix and match across model a bit if needed, 
  - have no worries about parameter tuning which is a bear otherwise, 
  - pull and save any model estimated, 
  - predict with any model fitted, 
  - and on and on ...

So, why wait? Let's get started.

```{r setup_chunk}
suppressPackageStartupMessages({
  library(magrittr)
  library(ggplot2)
  library(h2o)
  h2o.init()
})
    # intialize the h2o instance
```

If all went well above, we're in business. Read-in data. 

### Planning the UI and Outputs

* UI side will have the following:

  - 2 file input fields - one for calibration_data and one for pred_data.
  - variable selection for Y (default will be first variable)
  - variable selection for X (can drop variables like cust_ID etc)
  - check box for whether Y is a factor variable (i.e. classifn task?)
  - slider for choosing Training sample proportion (0 to 100, default=70)
  - slider for choosing Max Training time (10 to 100 secs, default=30)


* Output tabs will be:

  - Overview and example dataset tab
  - Data Summary (shows first 20 odd rows as HTML table)
  - Results Leaderboard Tab 
  - Best Model tab
  - Prediction output tab


Am reusing the telecom churn dataset. Behold.

```{r data_input}
path0 = "D:/"

# user inputs DF file
churnData = read.csv(paste0(path0, 'kaggle_Telco_Customer_Churn_cleaned.csv'), header=TRUE)
str(churnData)
data = churnData[1:2000,]  # taking a subset for demo

y = data$Churn  # UI selects Y variable for classifiers
X = data[,c(3:21)] # UI drops irrelevant variables from input DF
df0 = data.frame(y,X)  # DF created for use in rest of the app
pred_data = churnData[2001:3000, 3:21] # create fresh data for prediction

# more UI inputs needed
train_propn_ui = 0.7 # from UI, else 70% default. Slider as usual.
max_runtime_secs_ui = 30  # UI. slider from 10 to 100 secs. default=30
i = 3 # Have i=2 as default and a dropdown from 1-10 to select model_id number
```

OK. Now we're good to go. Will define the workflow and functionize it.

```{r func_def}

h2o_classifiers <- function(df0, train_propn_ui=0.7, pred_data=NULL){
  
  # Partition input Data
  set.seed(222)
  ind <- sample(2, nrow(df0), replace = TRUE, 
                prob = c(train_propn_ui, (1 - train_propn_ui))) # from UI
  train <- df0[ind==1,]
  test <- df0[ind==2,]

  # build H2O frames
  train_h2o = as.h2o(train)
  test_h2o = as.h2o(test)
  pred_h2o = as.h2o(pred_data)
  
  y <- "y"  # select DV variable name by user
  x <- setdiff(names(train), y)

  # Create automl obj by passing the mandatory parms.
  train_h2o[,y] <- as.factor(train_h2o[,y])  # only for classification Qs?
  system.time({
    aml <- h2o.automl(x = x, y = y,
                      training_frame = train_h2o,
                      max_runtime_secs = max_runtime_secs_ui) # from UI.
    }) # 46 s

  
  'Results Leaderboard Tab.'
  ## Viewing the leaderboard of different models.
  lb <- aml@leaderboard
  lb_df = as.data.frame(lb)
  print(lb_df)  # showas HTML table

  # plot leaderboard AUC scores for models estimated.
  plot1 = ggplot(data=lb_df, aes(seq(1:nrow(lb_df)), auc)) + 
          geom_line(colour = 'red') + 
          geom_point(colour = "blue") + 
          xlab("model number in leaderboard")
  plot1 # show below leaderboard table

  
  'Best model tab'
  # get details of the best fitting model
  best_model = aml@leader
  cat("===== Auto-ML recommended top model is: =====\n\n")
  print(best_model)
  
  ## get the i^th model from the leaderboard
  oth_model = h2o.getModel(as.vector(lb$model_id[i]))
  cat("===== Auto-ML recommended", i,"th model is: =====\n\n")
  print(oth_model)

  
  'Prediction Tab'
  ## Show Preds from best model (or oth_model) as UI chooses
  pred_out = h2o.predict(best_model, pred_h2o)
  pred_out_df = as.data.frame(pred_out)
  pred_out_df %>% head(15)  # display as HTML. Also as downloadable.
  
  } # func ends

```

OK. Time to test-drive now.

```{r test_drive}
system.time({ 
  h2o_classifiers(df0, train_propn_ui=0.7, pred_data=pred_data)
})
```

Ciao

Sudhir. May 2021